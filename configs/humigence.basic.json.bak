{
  "project": "humigence",
  "seed": 42,
  "model": {
    "repo": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "local_path": null,
    "use_flash_attn": true
  },
  "compute": {
    "gpus": 1,
    "gpu_type": "RTX_4080_16GB"
  },
  "data": {
    "raw_path": "data/raw/oasst1_conversations.jsonl",
    "processed_dir": "data/processed",
    "schema": "chat_messages",
    "max_seq_len": 1024,
    "packing": true,
    "split": {
      "train": 0.8,
      "val": 0.1,
      "test": 0.1
    },
    "template": "qwen_chat_basic_v1",
    "collator_windowing": "window",
    "window_overlap": 128,
    "real_mode_threshold": 1000
  },
  "train": {
    "precision_mode": "qlora_nf4",
    "lr": 0.0002,
    "scheduler": "cosine",
    "warmup_ratio": 0.03,
    "weight_decay": 0.0,
    "grad_clip": 1.0,
    "gradient_checkpointing": true,
    "tokens_per_step_target": 100000,
    "eval_every_steps": 500,
    "save_every_steps": 500,
    "epochs": 10,
    "lora": {
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj"
      ],
      "r": 16,
      "alpha": 32,
      "dropout": 0.05
    },
    "early_stopping": {
      "metric": "val_loss",
      "patience": 3,
      "min_delta": 0.002
    }
  },
  "eval": {
    "primary_metric": "val_loss",
    "curated_prompts_path": "configs/curated_eval_prompts.jsonl",
    "temperature_low": 0.2,
    "temperature_high": 0.7,
    "sampling_enabled": false
  },
  "acceptance": {
    "min_val_loss_improvement": 1.0,
    "min_val_improvement_pct": 1.0,
    "jitter_threshold": 20.0,
    "curated_threshold": 70.0
  },
  "export": {
    "artifacts_dir": "artifacts/humigence",
    "formats": [
      "peft_adapter"
    ]
  }
}